{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Comparison of Transfer Learning Models - Frontal View</h1>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p>Continuing with the model selection process, we proceed to train the three models demonstrating the highest accuracy from the previous step over a span of 10 epochs. It's important to note that, at present, we are not employing any form of data augmentations.</p>"
      ],
      "metadata": {
        "id": "wXLVc9e2jrjd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTZgHW5AxbRo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import inspect\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "MoCvG8lKHXjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCYTR-ZS9ut0",
        "outputId": "20a024dd-aeb5-4a64-b5b9-691893ba1db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "data_path = \"/content/drive/MyDrive/sve_F-bez augumentacije/Train\"\n",
        "n_folds =5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "all_files = glob.glob(os.path.join(data_path, '*/*'))\n",
        "labels = [os.path.basename(os.path.dirname(fp)) for fp in all_files]"
      ],
      "metadata": {
        "id": "NEJNRNoeImRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all available models\n",
        "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"
      ],
      "metadata": {
        "id": "XOATCQWS9rQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiJFPHCDSa88",
        "outputId": "691cc87c-3a8c-4a00-e8be-629562364e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_dict = {key: model_dictionary[key] for key in model_dictionary  if key in ['Xception', 'InceptionV3','ResNet50V2']}"
      ],
      "metadata": {
        "id": "OnVkY_hrFn_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_model_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptCeZ6bRT24w",
        "outputId": "f6acbcb7-7044-4856-cbe1-ea4bd5dafa35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_for_fold(train_files, val_files, img_size):\n",
        "    datagen = image.ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "    # Extracting the labels from the directory structure\n",
        "    train_labels = [os.path.basename(os.path.dirname(fp)) for fp in train_files]\n",
        "    val_labels = [os.path.basename(os.path.dirname(fp)) for fp in val_files]\n",
        "\n",
        "    train_gen = datagen.flow_from_dataframe(\n",
        "        dataframe=pd.DataFrame({'filename': train_files, 'class': train_labels}),\n",
        "        directory=None,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        class_mode=\"binary\",\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_gen = datagen.flow_from_dataframe(\n",
        "        dataframe=pd.DataFrame({'filename': val_files, 'class': val_labels}),\n",
        "        directory=None,\n",
        "        x_col=\"filename\",\n",
        "        y_col=\"class\",\n",
        "        class_mode=\"binary\",\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_gen, val_gen\n"
      ],
      "metadata": {
        "id": "_eAhE1t3HbaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_preprocces(img_size):\n",
        "  test_datagen = image.ImageDataGenerator(rescale=1./255.)\n",
        "  test_generator = test_datagen.flow_from_directory(\"/content/drive/MyDrive/sve_F-bez augumentacije/Test\",\n",
        "                                        target_size=img_size,\n",
        "                                        class_mode='binary',\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False)\n",
        "  return test_generator"
      ],
      "metadata": {
        "id": "UdiHoYdfJlnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_1,input_shape):\n",
        "    pre_trained_model = model_1(include_top=False, pooling='avg', input_shape=input_shape)\n",
        "    pre_trained_model.trainable = False\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(pre_trained_model)\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "P5NTxAvbJVng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over each model available in Keras\n",
        "model_benchmarks = {'model_name': [], 'num_model_params': [], 'validation_accuracy': [], 'test_accuracy': []}\n",
        "for model_name, model_1 in tqdm(list(new_model_dict.items())):\n",
        "    # Special handling for \"NASNetLarge\" since it requires input images with size (331,331)\n",
        "\n",
        "    fold_no = 1\n",
        "    all_acc = []\n",
        "    all_loss = []\n",
        "\n",
        "    for train_indices, val_indices in kfold.split(all_files,labels):\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Preprocess data and build model (assuming these functions are defined)\n",
        "        train_files = [all_files[i] for i in train_indices]\n",
        "        val_files = [all_files[i] for i in val_indices]\n",
        "        if 'NASNetLarge' in model_name:\n",
        "          img_size =(331,331)\n",
        "          input_shape =(331,331,3)\n",
        "          train_gen, val_gen = preprocess_data_for_fold(train_files, val_files, img_size)\n",
        "        elif 'InceptionResNetV2' or 'InceptionV3' or 'Xception' in model_name:\n",
        "          img_size=(299,299)\n",
        "          input_shape=(299,299,3)\n",
        "          train_gen, val_gen = preprocess_data_for_fold(train_files, val_files, img_size)\n",
        "        else:\n",
        "          img_size=(224,224)\n",
        "          input_shape=(224,224,3)\n",
        "          train_gen, val_gen = preprocess_data_for_fold(train_files, val_files, img_size)\n",
        "\n",
        "\n",
        "        model = build_model(model_1,input_shape)\n",
        "\n",
        "    # Fit data to model\n",
        "        history = model.fit(train_gen, epochs=10, validation_data=val_gen)\n",
        "\n",
        "    # Evaluate the model on validation set\n",
        "        scores = model.evaluate(val_gen, verbose=0)\n",
        "        print(f'Score for fold {fold_no}: Loss of {scores[0]}; Accuracy of {round(scores[1]*100, 2)}%')\n",
        "        all_acc.append(scores[1] * 100)\n",
        "        all_loss.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "        fold_no += 1\n",
        "\n",
        "# Provide average scores\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score per fold')\n",
        "    for i in range(len(all_acc)):\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'> Fold {i+1} - Loss: {all_loss[i]} - Accuracy: {all_acc[i]}%')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Average scores for all folds:')\n",
        "    print(f'> Accuracy: {np.mean(all_acc)} (+- {np.std(all_acc)})')\n",
        "    print(f'> Loss: {np.mean(all_loss)}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    if 'NASNetLarge' in model_name:\n",
        "        test_processed = test_preprocces(img_size)\n",
        "    elif 'InceptionResNetV2' or 'InceptionV3' or 'Xception' in model_name:\n",
        "        test_processed = test_preprocces(img_size)\n",
        "    else:\n",
        "        test_processed = test_preprocces(img_size)\n",
        "\n",
        "    test_acc = model.evaluate(test_processed)\n",
        "    predictions = model.predict(test_processed)\n",
        "    predicted_classes = np.where(predictions < 0.5, 0, 1)\n",
        "    true_classes = test_processed.classes\n",
        "    class_labels = list(test_processed.class_indices.keys())\n",
        "\n",
        "    report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "    print(report)\n",
        "\n",
        "    # Calculate all relevant metrics\n",
        "    model_benchmarks['model_name'].append(model_name)\n",
        "    model_benchmarks['num_model_params'].append(model.count_params())\n",
        "    model_benchmarks['validation_accuracy'].append(np.mean(all_acc))\n",
        "    model_benchmarks['test_accuracy'].append(test_acc[-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDBd5Pr1H5mN",
        "outputId": "d4a8205d-b9fd-4f85-8116-4b21c475e751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 43s 9s/step - loss: 0.7037 - accuracy: 0.5360 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 474ms/step - loss: 0.6926 - accuracy: 0.5360 - val_loss: 0.6377 - val_accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 0.6470 - accuracy: 0.6240 - val_loss: 0.6069 - val_accuracy: 0.6875\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 612ms/step - loss: 0.6158 - accuracy: 0.6880 - val_loss: 0.5801 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 0.5836 - accuracy: 0.7680 - val_loss: 0.5544 - val_accuracy: 0.7812\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.5572 - accuracy: 0.8080 - val_loss: 0.5369 - val_accuracy: 0.8125\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 494ms/step - loss: 0.5354 - accuracy: 0.8080 - val_loss: 0.5155 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.5148 - accuracy: 0.8480 - val_loss: 0.4997 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 500ms/step - loss: 0.4961 - accuracy: 0.8640 - val_loss: 0.4834 - val_accuracy: 0.9062\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 613ms/step - loss: 0.4792 - accuracy: 0.8560 - val_loss: 0.4724 - val_accuracy: 0.8438\n",
            "Score for fold 1: Loss of 0.47239863872528076; Accuracy of 84.38%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 9s 1s/step - loss: 0.7230 - accuracy: 0.4960 - val_loss: 0.6837 - val_accuracy: 0.5938\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 615ms/step - loss: 0.6713 - accuracy: 0.5680 - val_loss: 0.6593 - val_accuracy: 0.6562\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.6340 - accuracy: 0.6640 - val_loss: 0.6340 - val_accuracy: 0.6875\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 471ms/step - loss: 0.6023 - accuracy: 0.7680 - val_loss: 0.6146 - val_accuracy: 0.7812\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 0.5705 - accuracy: 0.7600 - val_loss: 0.5935 - val_accuracy: 0.8125\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.5553 - accuracy: 0.7600 - val_loss: 0.5887 - val_accuracy: 0.7812\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 0.5170 - accuracy: 0.8400 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 641ms/step - loss: 0.5071 - accuracy: 0.8080 - val_loss: 0.5602 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 469ms/step - loss: 0.4858 - accuracy: 0.8560 - val_loss: 0.5446 - val_accuracy: 0.8438\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.4724 - accuracy: 0.8400 - val_loss: 0.5481 - val_accuracy: 0.8438\n",
            "Score for fold 2: Loss of 0.5481194853782654; Accuracy of 84.38%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 17s 4s/step - loss: 0.8009 - accuracy: 0.5159 - val_loss: 0.8339 - val_accuracy: 0.4839\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.7881 - accuracy: 0.5079 - val_loss: 0.7986 - val_accuracy: 0.4839\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 0.6891 - accuracy: 0.5397 - val_loss: 0.7335 - val_accuracy: 0.4516\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 644ms/step - loss: 0.6711 - accuracy: 0.5714 - val_loss: 0.7154 - val_accuracy: 0.5161\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.6358 - accuracy: 0.6349 - val_loss: 0.6844 - val_accuracy: 0.4839\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 467ms/step - loss: 0.6048 - accuracy: 0.7302 - val_loss: 0.6840 - val_accuracy: 0.5806\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 473ms/step - loss: 0.5891 - accuracy: 0.6825 - val_loss: 0.6538 - val_accuracy: 0.6452\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 458ms/step - loss: 0.5595 - accuracy: 0.8095 - val_loss: 0.6325 - val_accuracy: 0.5484\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 480ms/step - loss: 0.5397 - accuracy: 0.8571 - val_loss: 0.6175 - val_accuracy: 0.5806\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.5223 - accuracy: 0.8333 - val_loss: 0.6066 - val_accuracy: 0.6774\n",
            "Score for fold 3: Loss of 0.6066405773162842; Accuracy of 67.74%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 8s 1s/step - loss: 0.7454 - accuracy: 0.5000 - val_loss: 0.6456 - val_accuracy: 0.5806\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.6855 - accuracy: 0.5476 - val_loss: 0.6215 - val_accuracy: 0.7742\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 487ms/step - loss: 0.6529 - accuracy: 0.6667 - val_loss: 0.5955 - val_accuracy: 0.8710\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 459ms/step - loss: 0.6198 - accuracy: 0.7143 - val_loss: 0.5771 - val_accuracy: 0.8387\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.5900 - accuracy: 0.7698 - val_loss: 0.5596 - val_accuracy: 0.8387\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 463ms/step - loss: 0.5648 - accuracy: 0.8175 - val_loss: 0.5426 - val_accuracy: 0.8710\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 476ms/step - loss: 0.5432 - accuracy: 0.8333 - val_loss: 0.5279 - val_accuracy: 0.8710\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 609ms/step - loss: 0.5215 - accuracy: 0.8175 - val_loss: 0.5145 - val_accuracy: 0.8387\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 655ms/step - loss: 0.5030 - accuracy: 0.8175 - val_loss: 0.5029 - val_accuracy: 0.8387\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 477ms/step - loss: 0.4877 - accuracy: 0.8254 - val_loss: 0.4911 - val_accuracy: 0.8065\n",
            "Score for fold 4: Loss of 0.49106183648109436; Accuracy of 80.65%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 10s 1s/step - loss: 0.7211 - accuracy: 0.4365 - val_loss: 0.7116 - val_accuracy: 0.4194\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 451ms/step - loss: 0.6630 - accuracy: 0.6032 - val_loss: 0.6790 - val_accuracy: 0.5161\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 594ms/step - loss: 0.6245 - accuracy: 0.7222 - val_loss: 0.6549 - val_accuracy: 0.5806\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 0.5844 - accuracy: 0.7937 - val_loss: 0.6389 - val_accuracy: 0.6129\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 3s 664ms/step - loss: 0.5506 - accuracy: 0.8095 - val_loss: 0.6157 - val_accuracy: 0.6452\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 633ms/step - loss: 0.5242 - accuracy: 0.8492 - val_loss: 0.6000 - val_accuracy: 0.6774\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.5005 - accuracy: 0.8175 - val_loss: 0.5919 - val_accuracy: 0.6774\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.4753 - accuracy: 0.8492 - val_loss: 0.5769 - val_accuracy: 0.7097\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 449ms/step - loss: 0.4521 - accuracy: 0.8810 - val_loss: 0.5657 - val_accuracy: 0.7097\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.4452 - accuracy: 0.8492 - val_loss: 0.5571 - val_accuracy: 0.6774\n",
            "Score for fold 5: Loss of 0.5570960640907288; Accuracy of 67.74%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.47239863872528076 - Accuracy: 84.375%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.5481194853782654 - Accuracy: 84.375%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.6066405773162842 - Accuracy: 67.7419364452362%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.49106183648109436 - Accuracy: 80.64516186714172%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.5570960640907288 - Accuracy: 67.7419364452362%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 76.97580695152283 (+- 7.661449080791209)\n",
            "> Loss: 0.5350633203983307\n",
            "------------------------------------------------------------------------\n",
            "Found 67 images belonging to 2 classes.\n",
            "3/3 [==============================] - 10s 5s/step - loss: 0.5898 - accuracy: 0.6866\n",
            "3/3 [==============================] - 3s 301ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [04:26<08:53, 266.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.66      0.76      0.70        33\n",
            "           M       0.72      0.62      0.67        34\n",
            "\n",
            "    accuracy                           0.69        67\n",
            "   macro avg       0.69      0.69      0.69        67\n",
            "weighted avg       0.69      0.69      0.69        67\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 14s 2s/step - loss: 0.7496 - accuracy: 0.4720 - val_loss: 0.7546 - val_accuracy: 0.4688\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 0.7058 - accuracy: 0.5040 - val_loss: 0.6889 - val_accuracy: 0.5312\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.6549 - accuracy: 0.6320 - val_loss: 0.6412 - val_accuracy: 0.5938\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.6318 - accuracy: 0.6400 - val_loss: 0.6037 - val_accuracy: 0.6875\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.5924 - accuracy: 0.7600 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 0.5729 - accuracy: 0.7120 - val_loss: 0.5454 - val_accuracy: 0.8125\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.5410 - accuracy: 0.7840 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 503ms/step - loss: 0.5222 - accuracy: 0.8320 - val_loss: 0.5003 - val_accuracy: 0.8125\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.5012 - accuracy: 0.8240 - val_loss: 0.4741 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 0.4769 - accuracy: 0.8480 - val_loss: 0.4588 - val_accuracy: 0.8125\n",
            "Score for fold 1: Loss of 0.4588044285774231; Accuracy of 81.25%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 828ms/step - loss: 0.6730 - accuracy: 0.5920 - val_loss: 0.6254 - val_accuracy: 0.6562\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 494ms/step - loss: 0.6190 - accuracy: 0.6880 - val_loss: 0.6080 - val_accuracy: 0.7500\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 597ms/step - loss: 0.5914 - accuracy: 0.6880 - val_loss: 0.5842 - val_accuracy: 0.7188\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.5647 - accuracy: 0.7440 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 604ms/step - loss: 0.5408 - accuracy: 0.7680 - val_loss: 0.5481 - val_accuracy: 0.7188\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 595ms/step - loss: 0.5070 - accuracy: 0.8000 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.4967 - accuracy: 0.7920 - val_loss: 0.5286 - val_accuracy: 0.7812\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 0.4766 - accuracy: 0.8160 - val_loss: 0.5053 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 490ms/step - loss: 0.4558 - accuracy: 0.8240 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.4433 - accuracy: 0.8320 - val_loss: 0.4842 - val_accuracy: 0.7500\n",
            "Score for fold 2: Loss of 0.4841760993003845; Accuracy of 75.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 15s 3s/step - loss: 0.7142 - accuracy: 0.5317 - val_loss: 0.7172 - val_accuracy: 0.4839\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.6688 - accuracy: 0.5952 - val_loss: 0.6761 - val_accuracy: 0.6452\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 0.6056 - accuracy: 0.7540 - val_loss: 0.6890 - val_accuracy: 0.6129\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.5763 - accuracy: 0.7143 - val_loss: 0.6561 - val_accuracy: 0.6452\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.5326 - accuracy: 0.8095 - val_loss: 0.6498 - val_accuracy: 0.6452\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 489ms/step - loss: 0.4984 - accuracy: 0.8333 - val_loss: 0.6421 - val_accuracy: 0.6129\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 473ms/step - loss: 0.4678 - accuracy: 0.8413 - val_loss: 0.6423 - val_accuracy: 0.7097\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.4470 - accuracy: 0.8651 - val_loss: 0.6440 - val_accuracy: 0.6774\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 592ms/step - loss: 0.4256 - accuracy: 0.8730 - val_loss: 0.6360 - val_accuracy: 0.7097\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 595ms/step - loss: 0.4093 - accuracy: 0.8492 - val_loss: 0.6327 - val_accuracy: 0.6774\n",
            "Score for fold 3: Loss of 0.6326853036880493; Accuracy of 67.74%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 835ms/step - loss: 0.7082 - accuracy: 0.5397 - val_loss: 0.6590 - val_accuracy: 0.6129\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 603ms/step - loss: 0.6602 - accuracy: 0.6190 - val_loss: 0.6118 - val_accuracy: 0.7419\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 0.6239 - accuracy: 0.6667 - val_loss: 0.5711 - val_accuracy: 0.7742\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 496ms/step - loss: 0.5858 - accuracy: 0.6746 - val_loss: 0.5520 - val_accuracy: 0.8710\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 478ms/step - loss: 0.5508 - accuracy: 0.7698 - val_loss: 0.5441 - val_accuracy: 0.8387\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 486ms/step - loss: 0.5266 - accuracy: 0.7857 - val_loss: 0.5179 - val_accuracy: 0.8065\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.5030 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.8065\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.4824 - accuracy: 0.8016 - val_loss: 0.4803 - val_accuracy: 0.8065\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 588ms/step - loss: 0.4646 - accuracy: 0.8175 - val_loss: 0.4711 - val_accuracy: 0.8065\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 641ms/step - loss: 0.4519 - accuracy: 0.8175 - val_loss: 0.4562 - val_accuracy: 0.8065\n",
            "Score for fold 4: Loss of 0.4561794400215149; Accuracy of 80.65%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 812ms/step - loss: 0.6963 - accuracy: 0.5238 - val_loss: 0.6950 - val_accuracy: 0.5161\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 598ms/step - loss: 0.6411 - accuracy: 0.6429 - val_loss: 0.6511 - val_accuracy: 0.5806\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 635ms/step - loss: 0.5998 - accuracy: 0.7540 - val_loss: 0.6191 - val_accuracy: 0.6774\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 481ms/step - loss: 0.5642 - accuracy: 0.7778 - val_loss: 0.5909 - val_accuracy: 0.6452\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 464ms/step - loss: 0.5359 - accuracy: 0.8175 - val_loss: 0.5711 - val_accuracy: 0.6452\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 479ms/step - loss: 0.5141 - accuracy: 0.8175 - val_loss: 0.5501 - val_accuracy: 0.7742\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 484ms/step - loss: 0.4873 - accuracy: 0.8333 - val_loss: 0.5343 - val_accuracy: 0.7097\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.4699 - accuracy: 0.8492 - val_loss: 0.5231 - val_accuracy: 0.7419\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 552ms/step - loss: 0.4511 - accuracy: 0.8571 - val_loss: 0.5076 - val_accuracy: 0.7419\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 542ms/step - loss: 0.4359 - accuracy: 0.8889 - val_loss: 0.4959 - val_accuracy: 0.7742\n",
            "Score for fold 5: Loss of 0.4958510100841522; Accuracy of 77.42%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.4588044285774231 - Accuracy: 81.25%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.4841760993003845 - Accuracy: 75.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.6326853036880493 - Accuracy: 67.7419364452362%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.4561794400215149 - Accuracy: 80.64516186714172%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.4958510100841522 - Accuracy: 77.4193525314331%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 76.4112901687622 (+- 4.888852749681646)\n",
            "> Loss: 0.5055392563343049\n",
            "------------------------------------------------------------------------\n",
            "Found 67 images belonging to 2 classes.\n",
            "3/3 [==============================] - 2s 810ms/step - loss: 0.4918 - accuracy: 0.7612\n",
            "3/3 [==============================] - 2s 249ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [07:30<03:37, 217.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.76      0.76      0.76        33\n",
            "           M       0.76      0.76      0.76        34\n",
            "\n",
            "    accuracy                           0.76        67\n",
            "   macro avg       0.76      0.76      0.76        67\n",
            "weighted avg       0.76      0.76      0.76        67\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 18s 3s/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6624 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 584ms/step - loss: 0.6650 - accuracy: 0.6320 - val_loss: 0.6237 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.6444 - accuracy: 0.7040 - val_loss: 0.5972 - val_accuracy: 0.7812\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 553ms/step - loss: 0.6159 - accuracy: 0.7200 - val_loss: 0.5702 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.6025 - accuracy: 0.7280 - val_loss: 0.5503 - val_accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.5891 - accuracy: 0.7360 - val_loss: 0.5282 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 852ms/step - loss: 0.5716 - accuracy: 0.7280 - val_loss: 0.5109 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 489ms/step - loss: 0.5602 - accuracy: 0.7360 - val_loss: 0.4984 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 533ms/step - loss: 0.5497 - accuracy: 0.7440 - val_loss: 0.4824 - val_accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 508ms/step - loss: 0.5378 - accuracy: 0.7520 - val_loss: 0.4686 - val_accuracy: 0.8750\n",
            "Score for fold 1: Loss of 0.46857455372810364; Accuracy of 87.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Found 125 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 853ms/step - loss: 0.6882 - accuracy: 0.5440 - val_loss: 0.6766 - val_accuracy: 0.5312\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.6567 - accuracy: 0.6560 - val_loss: 0.6568 - val_accuracy: 0.5312\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.6285 - accuracy: 0.7280 - val_loss: 0.6298 - val_accuracy: 0.7188\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.6150 - accuracy: 0.6960 - val_loss: 0.6119 - val_accuracy: 0.7812\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.5891 - accuracy: 0.7440 - val_loss: 0.5974 - val_accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 3s 629ms/step - loss: 0.5673 - accuracy: 0.7600 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 498ms/step - loss: 0.5551 - accuracy: 0.7760 - val_loss: 0.5776 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 500ms/step - loss: 0.5401 - accuracy: 0.7840 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.5276 - accuracy: 0.7760 - val_loss: 0.5543 - val_accuracy: 0.7188\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.5175 - accuracy: 0.7920 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
            "Score for fold 2: Loss of 0.5465152263641357; Accuracy of 71.88%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.7010 - accuracy: 0.5159 - val_loss: 0.6797 - val_accuracy: 0.6129\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.6606 - accuracy: 0.6270 - val_loss: 0.6618 - val_accuracy: 0.6129\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.6295 - accuracy: 0.7619 - val_loss: 0.6498 - val_accuracy: 0.7097\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6012 - accuracy: 0.7857 - val_loss: 0.6405 - val_accuracy: 0.6774\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 496ms/step - loss: 0.5755 - accuracy: 0.7937 - val_loss: 0.6342 - val_accuracy: 0.6452\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 612ms/step - loss: 0.5565 - accuracy: 0.7698 - val_loss: 0.6315 - val_accuracy: 0.6129\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 637ms/step - loss: 0.5376 - accuracy: 0.7778 - val_loss: 0.6240 - val_accuracy: 0.6452\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.5187 - accuracy: 0.8016 - val_loss: 0.6197 - val_accuracy: 0.6774\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 498ms/step - loss: 0.5045 - accuracy: 0.7857 - val_loss: 0.6167 - val_accuracy: 0.6774\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.4941 - accuracy: 0.8016 - val_loss: 0.6158 - val_accuracy: 0.6774\n",
            "Score for fold 3: Loss of 0.6157519221305847; Accuracy of 67.74%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 908ms/step - loss: 0.7015 - accuracy: 0.5000 - val_loss: 0.6982 - val_accuracy: 0.4839\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.6575 - accuracy: 0.6111 - val_loss: 0.6658 - val_accuracy: 0.5806\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.6341 - accuracy: 0.7540 - val_loss: 0.6517 - val_accuracy: 0.5806\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 528ms/step - loss: 0.6203 - accuracy: 0.7063 - val_loss: 0.6334 - val_accuracy: 0.6129\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.5952 - accuracy: 0.7381 - val_loss: 0.6196 - val_accuracy: 0.7097\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 652ms/step - loss: 0.5739 - accuracy: 0.7857 - val_loss: 0.6081 - val_accuracy: 0.7097\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 650ms/step - loss: 0.5571 - accuracy: 0.8095 - val_loss: 0.5980 - val_accuracy: 0.7097\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.5421 - accuracy: 0.8016 - val_loss: 0.5891 - val_accuracy: 0.7097\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.5298 - accuracy: 0.7857 - val_loss: 0.5813 - val_accuracy: 0.7097\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 522ms/step - loss: 0.5167 - accuracy: 0.7778 - val_loss: 0.5751 - val_accuracy: 0.7097\n",
            "Score for fold 4: Loss of 0.5750705599784851; Accuracy of 70.97%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Found 126 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 845ms/step - loss: 0.6875 - accuracy: 0.5794 - val_loss: 0.6758 - val_accuracy: 0.4839\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.6512 - accuracy: 0.6587 - val_loss: 0.6565 - val_accuracy: 0.6129\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 616ms/step - loss: 0.6201 - accuracy: 0.6984 - val_loss: 0.6413 - val_accuracy: 0.6774\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.5943 - accuracy: 0.7302 - val_loss: 0.6251 - val_accuracy: 0.6452\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 483ms/step - loss: 0.5736 - accuracy: 0.7381 - val_loss: 0.6148 - val_accuracy: 0.6129\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 502ms/step - loss: 0.5551 - accuracy: 0.7381 - val_loss: 0.6032 - val_accuracy: 0.6452\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.5385 - accuracy: 0.7540 - val_loss: 0.5943 - val_accuracy: 0.6452\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 532ms/step - loss: 0.5248 - accuracy: 0.7619 - val_loss: 0.5871 - val_accuracy: 0.6452\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.5105 - accuracy: 0.7698 - val_loss: 0.5813 - val_accuracy: 0.6452\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 3s 629ms/step - loss: 0.5009 - accuracy: 0.7698 - val_loss: 0.5758 - val_accuracy: 0.6452\n",
            "Score for fold 5: Loss of 0.5757730007171631; Accuracy of 64.52%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.46857455372810364 - Accuracy: 87.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.5465152263641357 - Accuracy: 71.875%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.6157519221305847 - Accuracy: 67.7419364452362%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.5750705599784851 - Accuracy: 70.96773982048035%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.5757730007171631 - Accuracy: 64.51612710952759%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 72.52016067504883 (+- 7.92613157998328)\n",
            "> Loss: 0.5563370525836945\n",
            "------------------------------------------------------------------------\n",
            "Found 67 images belonging to 2 classes.\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.5569 - accuracy: 0.7612\n",
            "3/3 [==============================] - 2s 281ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [10:41<00:00, 213.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.77      0.73      0.75        33\n",
            "           M       0.75      0.79      0.77        34\n",
            "\n",
            "    accuracy                           0.76        67\n",
            "   macro avg       0.76      0.76      0.76        67\n",
            "weighted avg       0.76      0.76      0.76        67\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Results to DataFrame for easy viewing\n",
        "benchmark_df = pd.DataFrame(model_benchmarks)\n",
        "benchmark_df.sort_values('num_model_params', inplace=True) # sort in ascending order of num_model_params column\n",
        "benchmark_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "KYvHlti8Kjb1",
        "outputId": "f4129e98-3630-4035-89fd-fd1be3afa018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    model_name  num_model_params  validation_accuracy  test_accuracy\n",
              "2     Xception          20863529            72.520161       0.761194\n",
              "0  InceptionV3          21804833            76.975807       0.686567\n",
              "1   ResNet50V2          23566849            76.411290       0.761194"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2ec6ba8-f904-44a6-9f19-5e31ca55c241\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>num_model_params</th>\n",
              "      <th>validation_accuracy</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xception</td>\n",
              "      <td>20863529</td>\n",
              "      <td>72.520161</td>\n",
              "      <td>0.761194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>InceptionV3</td>\n",
              "      <td>21804833</td>\n",
              "      <td>76.975807</td>\n",
              "      <td>0.686567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ResNet50V2</td>\n",
              "      <td>23566849</td>\n",
              "      <td>76.411290</td>\n",
              "      <td>0.761194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2ec6ba8-f904-44a6-9f19-5e31ca55c241')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2ec6ba8-f904-44a6-9f19-5e31ca55c241 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2ec6ba8-f904-44a6-9f19-5e31ca55c241');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-757231ed-2447-428e-ad1f-a655b1169502\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-757231ed-2447-428e-ad1f-a655b1169502')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-757231ed-2447-428e-ad1f-a655b1169502 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}