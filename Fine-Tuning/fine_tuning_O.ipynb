{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFbRsIMgcSWx"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-u-ea-cbQc",
        "outputId": "93ff1dde-6677-472a-c3f8-2468dd782a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "XYFwloJ5cdST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42"
      ],
      "metadata": {
        "id": "zEPu42J3ciRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(batch_size, img_size):\n",
        "  train_gen = image.ImageDataGenerator(rescale = 1./255.,\n",
        "                                       validation_split=0.15,\n",
        "                                       rotation_range=15,  # rotate the image up to 15 degrees\n",
        "                                       brightness_range = [0.2, 1.0],\n",
        "                                      )\n",
        "  train_generator = train_gen.flow_from_directory(\n",
        "                                      \"/content/drive/MyDrive/sve_O - bez augumentacija/Train\",\n",
        "                                      target_size = img_size,\n",
        "                                      class_mode = \"binary\",\n",
        "                                      shuffle = True,\n",
        "                                      batch_size = batch_size,\n",
        "                                      subset='training',\n",
        "                                      seed=seed\n",
        "                                      )\n",
        "\n",
        "  val_generator = train_gen.flow_from_directory(\n",
        "                                      \"/content/drive/MyDrive/sve_O - bez augumentacija/Train\",\n",
        "                                      target_size = img_size,\n",
        "                                      class_mode = \"binary\",\n",
        "                                      shuffle = True,\n",
        "                                      batch_size = batch_size,\n",
        "                                      subset='validation',\n",
        "                                      seed=seed\n",
        "                                      )\n",
        "\n",
        "  test_datagen = image.ImageDataGenerator(rescale = 1./255.)\n",
        "  test_generator = test_datagen.flow_from_directory(\"/content/drive/MyDrive/sve_O - bez augumentacija/Test\",\n",
        "                                         target_size = img_size,\n",
        "                                         class_mode = 'binary',\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle= False)\n",
        "  return train_generator,val_generator,test_generator"
      ],
      "metadata": {
        "id": "dxKKIYlrcizo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_processed_224, validation_processed_224, test_processed_224 = preprocess_data(batch_size, img_size=[224,224])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaqYlPJ5cm5V",
        "outputId": "f031c269-2087-4779-96ba-de5a8b705bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 135 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n",
            "Found 67 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train =train_processed_224.samples\n",
        "num_iterations = int(num_train/batch_size)"
      ],
      "metadata": {
        "id": "9YxokBsLcovt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"
      ],
      "metadata": {
        "id": "TvTiE148c5xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_dict = {key: model_dictionary[key] for key in model_dictionary  if key in ['ResNet50V2']}"
      ],
      "metadata": {
        "id": "9oY_5r3gc6uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model in tqdm(new_model_dict.items()):\n",
        "  m_name = model_name\n",
        "  model1 = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynJ90__3c9Is",
        "outputId": "151e7dc0-1b39-4834-910e-8f2f16330de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1834.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(224,224,3)\n",
        "train_processed = train_processed_224\n",
        "validation_processed = validation_processed_224\n",
        "test_processed = test_processed_224\n",
        "\n",
        "# load the pre-trained model with global average pooling as the last layer and freeze the model weights\n",
        "pre_trained_model = model1(include_top=False, pooling='avg', input_shape=input_shape)\n",
        "#pre_trained_model.trainable = False\n",
        "for layer in pre_trained_model.layers:\n",
        "   layer.trainable = False\n",
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6qPMUUCdB6z",
        "outputId": "9f2cb31c-e05c-411b-b170-7cc2302a4aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_conv[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (Ba  (None, 56, 56, 64)           256       ['pool1_pool[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (  (None, 56, 56, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4096      ['conv2_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
            "                                                                     'conv2_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 28, 28, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 28, 28, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 28, 28, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 28, 28, 256)          0         ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 28, 28, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)      (None, 28, 28, 256)          0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'conv2_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (Ba  (None, 28, 28, 256)          1024      ['conv2_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (  (None, 28, 28, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv3_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
            "                                                                     'conv3_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block4_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 14, 14, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 14, 14, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 14, 14, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 512)          0         ['conv3_block3_out[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 14, 14, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)      (None, 14, 14, 512)          0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv3_block4_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (Ba  (None, 14, 14, 512)          2048      ['conv3_block4_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (  (None, 14, 14, 512)          0         ['conv4_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131072    ['conv4_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv4_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_conv[0][0]', \n",
            "                                                                     'conv4_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block3_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block4_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block4_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block4_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block4_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block5_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block5_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block5_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block5_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block6_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block6_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block6_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 1024)           0         ['conv4_block5_out[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)      (None, 7, 7, 1024)           0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv4_block6_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (  (None, 7, 7, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524288    ['conv5_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
            "                                                                     'conv5_block1_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
            " Activation)                                                        ']                            \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
            " D)                                                                 0]']                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
            " dding2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_conv[0][0]'] \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalizatio  (None, 7, 7, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " post_relu (Activation)      (None, 7, 7, 2048)           0         ['post_bn[0][0]']             \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['post_relu[0][0]']           \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23564800 (89.89 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(pre_trained_model.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "expzPJaffxYN",
        "outputId": "49435922-c987-4f12-f643-7136f58cfc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 False\n",
            "1 conv1_pad False\n",
            "2 conv1_conv False\n",
            "3 pool1_pad False\n",
            "4 pool1_pool False\n",
            "5 conv2_block1_preact_bn False\n",
            "6 conv2_block1_preact_relu False\n",
            "7 conv2_block1_1_conv False\n",
            "8 conv2_block1_1_bn False\n",
            "9 conv2_block1_1_relu False\n",
            "10 conv2_block1_2_pad False\n",
            "11 conv2_block1_2_conv False\n",
            "12 conv2_block1_2_bn False\n",
            "13 conv2_block1_2_relu False\n",
            "14 conv2_block1_0_conv False\n",
            "15 conv2_block1_3_conv False\n",
            "16 conv2_block1_out False\n",
            "17 conv2_block2_preact_bn False\n",
            "18 conv2_block2_preact_relu False\n",
            "19 conv2_block2_1_conv False\n",
            "20 conv2_block2_1_bn False\n",
            "21 conv2_block2_1_relu False\n",
            "22 conv2_block2_2_pad False\n",
            "23 conv2_block2_2_conv False\n",
            "24 conv2_block2_2_bn False\n",
            "25 conv2_block2_2_relu False\n",
            "26 conv2_block2_3_conv False\n",
            "27 conv2_block2_out False\n",
            "28 conv2_block3_preact_bn False\n",
            "29 conv2_block3_preact_relu False\n",
            "30 conv2_block3_1_conv False\n",
            "31 conv2_block3_1_bn False\n",
            "32 conv2_block3_1_relu False\n",
            "33 conv2_block3_2_pad False\n",
            "34 conv2_block3_2_conv False\n",
            "35 conv2_block3_2_bn False\n",
            "36 conv2_block3_2_relu False\n",
            "37 max_pooling2d False\n",
            "38 conv2_block3_3_conv False\n",
            "39 conv2_block3_out False\n",
            "40 conv3_block1_preact_bn False\n",
            "41 conv3_block1_preact_relu False\n",
            "42 conv3_block1_1_conv False\n",
            "43 conv3_block1_1_bn False\n",
            "44 conv3_block1_1_relu False\n",
            "45 conv3_block1_2_pad False\n",
            "46 conv3_block1_2_conv False\n",
            "47 conv3_block1_2_bn False\n",
            "48 conv3_block1_2_relu False\n",
            "49 conv3_block1_0_conv False\n",
            "50 conv3_block1_3_conv False\n",
            "51 conv3_block1_out False\n",
            "52 conv3_block2_preact_bn False\n",
            "53 conv3_block2_preact_relu False\n",
            "54 conv3_block2_1_conv False\n",
            "55 conv3_block2_1_bn False\n",
            "56 conv3_block2_1_relu False\n",
            "57 conv3_block2_2_pad False\n",
            "58 conv3_block2_2_conv False\n",
            "59 conv3_block2_2_bn False\n",
            "60 conv3_block2_2_relu False\n",
            "61 conv3_block2_3_conv False\n",
            "62 conv3_block2_out False\n",
            "63 conv3_block3_preact_bn False\n",
            "64 conv3_block3_preact_relu False\n",
            "65 conv3_block3_1_conv False\n",
            "66 conv3_block3_1_bn False\n",
            "67 conv3_block3_1_relu False\n",
            "68 conv3_block3_2_pad False\n",
            "69 conv3_block3_2_conv False\n",
            "70 conv3_block3_2_bn False\n",
            "71 conv3_block3_2_relu False\n",
            "72 conv3_block3_3_conv False\n",
            "73 conv3_block3_out False\n",
            "74 conv3_block4_preact_bn False\n",
            "75 conv3_block4_preact_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_pad False\n",
            "80 conv3_block4_2_conv False\n",
            "81 conv3_block4_2_bn False\n",
            "82 conv3_block4_2_relu False\n",
            "83 max_pooling2d_1 False\n",
            "84 conv3_block4_3_conv False\n",
            "85 conv3_block4_out False\n",
            "86 conv4_block1_preact_bn False\n",
            "87 conv4_block1_preact_relu False\n",
            "88 conv4_block1_1_conv False\n",
            "89 conv4_block1_1_bn False\n",
            "90 conv4_block1_1_relu False\n",
            "91 conv4_block1_2_pad False\n",
            "92 conv4_block1_2_conv False\n",
            "93 conv4_block1_2_bn False\n",
            "94 conv4_block1_2_relu False\n",
            "95 conv4_block1_0_conv False\n",
            "96 conv4_block1_3_conv False\n",
            "97 conv4_block1_out False\n",
            "98 conv4_block2_preact_bn False\n",
            "99 conv4_block2_preact_relu False\n",
            "100 conv4_block2_1_conv False\n",
            "101 conv4_block2_1_bn False\n",
            "102 conv4_block2_1_relu False\n",
            "103 conv4_block2_2_pad False\n",
            "104 conv4_block2_2_conv False\n",
            "105 conv4_block2_2_bn False\n",
            "106 conv4_block2_2_relu False\n",
            "107 conv4_block2_3_conv False\n",
            "108 conv4_block2_out False\n",
            "109 conv4_block3_preact_bn False\n",
            "110 conv4_block3_preact_relu False\n",
            "111 conv4_block3_1_conv False\n",
            "112 conv4_block3_1_bn False\n",
            "113 conv4_block3_1_relu False\n",
            "114 conv4_block3_2_pad False\n",
            "115 conv4_block3_2_conv False\n",
            "116 conv4_block3_2_bn False\n",
            "117 conv4_block3_2_relu False\n",
            "118 conv4_block3_3_conv False\n",
            "119 conv4_block3_out False\n",
            "120 conv4_block4_preact_bn False\n",
            "121 conv4_block4_preact_relu False\n",
            "122 conv4_block4_1_conv False\n",
            "123 conv4_block4_1_bn False\n",
            "124 conv4_block4_1_relu False\n",
            "125 conv4_block4_2_pad False\n",
            "126 conv4_block4_2_conv False\n",
            "127 conv4_block4_2_bn False\n",
            "128 conv4_block4_2_relu False\n",
            "129 conv4_block4_3_conv False\n",
            "130 conv4_block4_out False\n",
            "131 conv4_block5_preact_bn False\n",
            "132 conv4_block5_preact_relu False\n",
            "133 conv4_block5_1_conv False\n",
            "134 conv4_block5_1_bn False\n",
            "135 conv4_block5_1_relu False\n",
            "136 conv4_block5_2_pad False\n",
            "137 conv4_block5_2_conv False\n",
            "138 conv4_block5_2_bn False\n",
            "139 conv4_block5_2_relu False\n",
            "140 conv4_block5_3_conv False\n",
            "141 conv4_block5_out False\n",
            "142 conv4_block6_preact_bn False\n",
            "143 conv4_block6_preact_relu False\n",
            "144 conv4_block6_1_conv False\n",
            "145 conv4_block6_1_bn False\n",
            "146 conv4_block6_1_relu False\n",
            "147 conv4_block6_2_pad False\n",
            "148 conv4_block6_2_conv False\n",
            "149 conv4_block6_2_bn False\n",
            "150 conv4_block6_2_relu False\n",
            "151 max_pooling2d_2 False\n",
            "152 conv4_block6_3_conv False\n",
            "153 conv4_block6_out False\n",
            "154 conv5_block1_preact_bn False\n",
            "155 conv5_block1_preact_relu False\n",
            "156 conv5_block1_1_conv False\n",
            "157 conv5_block1_1_bn False\n",
            "158 conv5_block1_1_relu False\n",
            "159 conv5_block1_2_pad False\n",
            "160 conv5_block1_2_conv False\n",
            "161 conv5_block1_2_bn False\n",
            "162 conv5_block1_2_relu False\n",
            "163 conv5_block1_0_conv False\n",
            "164 conv5_block1_3_conv False\n",
            "165 conv5_block1_out False\n",
            "166 conv5_block2_preact_bn False\n",
            "167 conv5_block2_preact_relu False\n",
            "168 conv5_block2_1_conv False\n",
            "169 conv5_block2_1_bn False\n",
            "170 conv5_block2_1_relu False\n",
            "171 conv5_block2_2_pad False\n",
            "172 conv5_block2_2_conv False\n",
            "173 conv5_block2_2_bn False\n",
            "174 conv5_block2_2_relu False\n",
            "175 conv5_block2_3_conv False\n",
            "176 conv5_block2_out False\n",
            "177 conv5_block3_preact_bn False\n",
            "178 conv5_block3_preact_relu False\n",
            "179 conv5_block3_1_conv False\n",
            "180 conv5_block3_1_bn False\n",
            "181 conv5_block3_1_relu False\n",
            "182 conv5_block3_2_pad False\n",
            "183 conv5_block3_2_conv False\n",
            "184 conv5_block3_2_bn False\n",
            "185 conv5_block3_2_relu False\n",
            "186 conv5_block3_3_conv False\n",
            "187 conv5_block3_out False\n",
            "188 post_bn False\n",
            "189 post_relu False\n",
            "190 avg_pool False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# custom modifications on top of pre-trained model\n",
        "clf_model = tf.keras.models.Sequential()\n",
        "clf_model.add(pre_trained_model)\n",
        "clf_model.add(tf.keras.layers.BatchNormalization())\n",
        "clf_model.add(tf.keras.layers.Dropout(0.3))\n",
        "clf_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "clf_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "clf_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BD4VVCOdDBL",
        "outputId": "9d3feb9d-c92c-481d-f659-cb774b2906c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 2048)              8192      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23575041 (89.93 MB)\n",
            "Trainable params: 6145 (24.00 KB)\n",
            "Non-trainable params: 23568896 (89.91 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 5:\n",
        "        lr *= 0.5\n",
        "    return lr\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ],
      "metadata": {
        "id": "sIrGcspzd8Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = clf_model.fit(train_processed, epochs=10, validation_data=validation_processed,\n",
        "                            steps_per_epoch=num_iterations, callbacks=[lr_callback])\n",
        "test_acc = clf_model.evaluate(test_processed)\n",
        "predictions = clf_model.predict(test_processed)\n",
        "predicted_classes = np.where(predictions < 0.5, 0, 1)\n",
        "true_classes = test_processed.classes\n",
        "class_labels = list(test_processed.class_indices.keys())\n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25x2_Zb0JMwz",
        "outputId": "115d1068-a858-4a39-ba67-bddab821def9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.2149 - accuracy: 0.9223 - val_loss: 0.2324 - val_accuracy: 0.9545 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.1714 - accuracy: 0.9417 - val_loss: 0.3035 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.2136 - accuracy: 0.9219 - val_loss: 0.3202 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.1830 - accuracy: 0.9417 - val_loss: 0.2235 - val_accuracy: 0.9545 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.1781 - accuracy: 0.9609 - val_loss: 0.2936 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1684 - accuracy: 0.9612 - val_loss: 0.1973 - val_accuracy: 0.9545 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 897ms/step - loss: 0.1606 - accuracy: 0.9320 - val_loss: 0.2447 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 705ms/step - loss: 0.1564 - accuracy: 0.9515 - val_loss: 0.2702 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.1789 - accuracy: 0.9029 - val_loss: 0.2040 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 3s 808ms/step - loss: 0.1480 - accuracy: 0.9609 - val_loss: 0.3302 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "3/3 [==============================] - 1s 136ms/step - loss: 0.4651 - accuracy: 0.7910\n",
            "3/3 [==============================] - 1s 163ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.77      0.82      0.79        33\n",
            "           M       0.81      0.76      0.79        34\n",
            "\n",
            "    accuracy                           0.79        67\n",
            "   macro avg       0.79      0.79      0.79        67\n",
            "weighted avg       0.79      0.79      0.79        67\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the last few layers of the base model\n",
        "for layer in pre_trained_model.layers[154:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "iE9EbYj3DO3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(pre_trained_model.layers):\n",
        "   print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhNUOyDaFH2L",
        "outputId": "bad2af9e-0ff3-4e79-8ac5-be54487f6e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 False\n",
            "1 conv1_pad False\n",
            "2 conv1_conv False\n",
            "3 pool1_pad False\n",
            "4 pool1_pool False\n",
            "5 conv2_block1_preact_bn False\n",
            "6 conv2_block1_preact_relu False\n",
            "7 conv2_block1_1_conv False\n",
            "8 conv2_block1_1_bn False\n",
            "9 conv2_block1_1_relu False\n",
            "10 conv2_block1_2_pad False\n",
            "11 conv2_block1_2_conv False\n",
            "12 conv2_block1_2_bn False\n",
            "13 conv2_block1_2_relu False\n",
            "14 conv2_block1_0_conv False\n",
            "15 conv2_block1_3_conv False\n",
            "16 conv2_block1_out False\n",
            "17 conv2_block2_preact_bn False\n",
            "18 conv2_block2_preact_relu False\n",
            "19 conv2_block2_1_conv False\n",
            "20 conv2_block2_1_bn False\n",
            "21 conv2_block2_1_relu False\n",
            "22 conv2_block2_2_pad False\n",
            "23 conv2_block2_2_conv False\n",
            "24 conv2_block2_2_bn False\n",
            "25 conv2_block2_2_relu False\n",
            "26 conv2_block2_3_conv False\n",
            "27 conv2_block2_out False\n",
            "28 conv2_block3_preact_bn False\n",
            "29 conv2_block3_preact_relu False\n",
            "30 conv2_block3_1_conv False\n",
            "31 conv2_block3_1_bn False\n",
            "32 conv2_block3_1_relu False\n",
            "33 conv2_block3_2_pad False\n",
            "34 conv2_block3_2_conv False\n",
            "35 conv2_block3_2_bn False\n",
            "36 conv2_block3_2_relu False\n",
            "37 max_pooling2d False\n",
            "38 conv2_block3_3_conv False\n",
            "39 conv2_block3_out False\n",
            "40 conv3_block1_preact_bn False\n",
            "41 conv3_block1_preact_relu False\n",
            "42 conv3_block1_1_conv False\n",
            "43 conv3_block1_1_bn False\n",
            "44 conv3_block1_1_relu False\n",
            "45 conv3_block1_2_pad False\n",
            "46 conv3_block1_2_conv False\n",
            "47 conv3_block1_2_bn False\n",
            "48 conv3_block1_2_relu False\n",
            "49 conv3_block1_0_conv False\n",
            "50 conv3_block1_3_conv False\n",
            "51 conv3_block1_out False\n",
            "52 conv3_block2_preact_bn False\n",
            "53 conv3_block2_preact_relu False\n",
            "54 conv3_block2_1_conv False\n",
            "55 conv3_block2_1_bn False\n",
            "56 conv3_block2_1_relu False\n",
            "57 conv3_block2_2_pad False\n",
            "58 conv3_block2_2_conv False\n",
            "59 conv3_block2_2_bn False\n",
            "60 conv3_block2_2_relu False\n",
            "61 conv3_block2_3_conv False\n",
            "62 conv3_block2_out False\n",
            "63 conv3_block3_preact_bn False\n",
            "64 conv3_block3_preact_relu False\n",
            "65 conv3_block3_1_conv False\n",
            "66 conv3_block3_1_bn False\n",
            "67 conv3_block3_1_relu False\n",
            "68 conv3_block3_2_pad False\n",
            "69 conv3_block3_2_conv False\n",
            "70 conv3_block3_2_bn False\n",
            "71 conv3_block3_2_relu False\n",
            "72 conv3_block3_3_conv False\n",
            "73 conv3_block3_out False\n",
            "74 conv3_block4_preact_bn False\n",
            "75 conv3_block4_preact_relu False\n",
            "76 conv3_block4_1_conv False\n",
            "77 conv3_block4_1_bn False\n",
            "78 conv3_block4_1_relu False\n",
            "79 conv3_block4_2_pad False\n",
            "80 conv3_block4_2_conv False\n",
            "81 conv3_block4_2_bn False\n",
            "82 conv3_block4_2_relu False\n",
            "83 max_pooling2d_1 False\n",
            "84 conv3_block4_3_conv False\n",
            "85 conv3_block4_out False\n",
            "86 conv4_block1_preact_bn False\n",
            "87 conv4_block1_preact_relu False\n",
            "88 conv4_block1_1_conv False\n",
            "89 conv4_block1_1_bn False\n",
            "90 conv4_block1_1_relu False\n",
            "91 conv4_block1_2_pad False\n",
            "92 conv4_block1_2_conv False\n",
            "93 conv4_block1_2_bn False\n",
            "94 conv4_block1_2_relu False\n",
            "95 conv4_block1_0_conv False\n",
            "96 conv4_block1_3_conv False\n",
            "97 conv4_block1_out False\n",
            "98 conv4_block2_preact_bn False\n",
            "99 conv4_block2_preact_relu False\n",
            "100 conv4_block2_1_conv False\n",
            "101 conv4_block2_1_bn False\n",
            "102 conv4_block2_1_relu False\n",
            "103 conv4_block2_2_pad False\n",
            "104 conv4_block2_2_conv False\n",
            "105 conv4_block2_2_bn False\n",
            "106 conv4_block2_2_relu False\n",
            "107 conv4_block2_3_conv False\n",
            "108 conv4_block2_out False\n",
            "109 conv4_block3_preact_bn False\n",
            "110 conv4_block3_preact_relu False\n",
            "111 conv4_block3_1_conv False\n",
            "112 conv4_block3_1_bn False\n",
            "113 conv4_block3_1_relu False\n",
            "114 conv4_block3_2_pad False\n",
            "115 conv4_block3_2_conv False\n",
            "116 conv4_block3_2_bn False\n",
            "117 conv4_block3_2_relu False\n",
            "118 conv4_block3_3_conv False\n",
            "119 conv4_block3_out False\n",
            "120 conv4_block4_preact_bn False\n",
            "121 conv4_block4_preact_relu False\n",
            "122 conv4_block4_1_conv False\n",
            "123 conv4_block4_1_bn False\n",
            "124 conv4_block4_1_relu False\n",
            "125 conv4_block4_2_pad False\n",
            "126 conv4_block4_2_conv False\n",
            "127 conv4_block4_2_bn False\n",
            "128 conv4_block4_2_relu False\n",
            "129 conv4_block4_3_conv False\n",
            "130 conv4_block4_out False\n",
            "131 conv4_block5_preact_bn False\n",
            "132 conv4_block5_preact_relu False\n",
            "133 conv4_block5_1_conv False\n",
            "134 conv4_block5_1_bn False\n",
            "135 conv4_block5_1_relu False\n",
            "136 conv4_block5_2_pad False\n",
            "137 conv4_block5_2_conv False\n",
            "138 conv4_block5_2_bn False\n",
            "139 conv4_block5_2_relu False\n",
            "140 conv4_block5_3_conv False\n",
            "141 conv4_block5_out False\n",
            "142 conv4_block6_preact_bn False\n",
            "143 conv4_block6_preact_relu False\n",
            "144 conv4_block6_1_conv False\n",
            "145 conv4_block6_1_bn False\n",
            "146 conv4_block6_1_relu False\n",
            "147 conv4_block6_2_pad False\n",
            "148 conv4_block6_2_conv False\n",
            "149 conv4_block6_2_bn False\n",
            "150 conv4_block6_2_relu False\n",
            "151 max_pooling2d_2 False\n",
            "152 conv4_block6_3_conv False\n",
            "153 conv4_block6_out False\n",
            "154 conv5_block1_preact_bn True\n",
            "155 conv5_block1_preact_relu True\n",
            "156 conv5_block1_1_conv True\n",
            "157 conv5_block1_1_bn True\n",
            "158 conv5_block1_1_relu True\n",
            "159 conv5_block1_2_pad True\n",
            "160 conv5_block1_2_conv True\n",
            "161 conv5_block1_2_bn True\n",
            "162 conv5_block1_2_relu True\n",
            "163 conv5_block1_0_conv True\n",
            "164 conv5_block1_3_conv True\n",
            "165 conv5_block1_out True\n",
            "166 conv5_block2_preact_bn True\n",
            "167 conv5_block2_preact_relu True\n",
            "168 conv5_block2_1_conv True\n",
            "169 conv5_block2_1_bn True\n",
            "170 conv5_block2_1_relu True\n",
            "171 conv5_block2_2_pad True\n",
            "172 conv5_block2_2_conv True\n",
            "173 conv5_block2_2_bn True\n",
            "174 conv5_block2_2_relu True\n",
            "175 conv5_block2_3_conv True\n",
            "176 conv5_block2_out True\n",
            "177 conv5_block3_preact_bn True\n",
            "178 conv5_block3_preact_relu True\n",
            "179 conv5_block3_1_conv True\n",
            "180 conv5_block3_1_bn True\n",
            "181 conv5_block3_1_relu True\n",
            "182 conv5_block3_2_pad True\n",
            "183 conv5_block3_2_conv True\n",
            "184 conv5_block3_2_bn True\n",
            "185 conv5_block3_2_relu True\n",
            "186 conv5_block3_3_conv True\n",
            "187 conv5_block3_out True\n",
            "188 post_bn True\n",
            "189 post_relu True\n",
            "190 avg_pool True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "56odaGmUdVoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = clf_model.fit(train_processed, epochs=100, validation_data=validation_processed,\n",
        "                            steps_per_epoch=num_iterations,callbacks=[lr_callback])\n",
        "test_acc = clf_model.evaluate(test_processed)\n",
        "predictions = clf_model.predict(test_processed)\n",
        "predicted_classes = np.where(predictions < 0.5, 0, 1)\n",
        "true_classes = test_processed.classes\n",
        "class_labels = list(test_processed.class_indices.keys())\n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "dLA6xdINePN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf09dab-22e5-4d64-a6e6-d9193e126833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0169 - accuracy: 0.9922 - val_loss: 2.1834 - val_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1347 - val_accuracy: 0.6364 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.0165 - accuracy: 0.9903 - val_loss: 1.6380 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 3s 835ms/step - loss: 0.0554 - accuracy: 0.9766 - val_loss: 0.1935 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.9760 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 4s 882ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.0140 - accuracy: 0.9903 - val_loss: 0.7311 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 3s 812ms/step - loss: 3.4467e-04 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 3s 801ms/step - loss: 4.9351e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6230 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 3s 886ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 3s 713ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 3s 896ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0173 - accuracy: 0.9903 - val_loss: 0.4810 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 3s 939ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 3s 935ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 4.1460e-04 - accuracy: 1.0000 - val_loss: 0.8876 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 4s 920ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0670 - accuracy: 0.9709 - val_loss: 0.5057 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 4s 978ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.1547 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 4s 888ms/step - loss: 0.1035 - accuracy: 0.9806 - val_loss: 0.4987 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0201 - accuracy: 0.9903 - val_loss: 0.3748 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 3s 822ms/step - loss: 0.0938 - accuracy: 0.9844 - val_loss: 0.7206 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 4s 946ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0210 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 3s 823ms/step - loss: 0.0116 - accuracy: 0.9922 - val_loss: 0.5222 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 4s 911ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5722 - val_accuracy: 0.6818 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0469 - accuracy: 0.9903 - val_loss: 2.1750 - val_accuracy: 0.5909 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 4s 899ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6444 - val_accuracy: 0.6364 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 3s 815ms/step - loss: 0.0154 - accuracy: 0.9922 - val_loss: 1.6185 - val_accuracy: 0.6818 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.0548 - accuracy: 0.9903 - val_loss: 1.4554 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0672 - accuracy: 0.9709 - val_loss: 0.4913 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 4s 866ms/step - loss: 0.0203 - accuracy: 0.9922 - val_loss: 0.1564 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 4s 928ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 4s 926ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 3s 904ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 4s 909ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 3s 884ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.4401 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.0246 - accuracy: 0.9806 - val_loss: 1.0405 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 3s 904ms/step - loss: 0.0572 - accuracy: 0.9612 - val_loss: 0.2687 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 3s 877ms/step - loss: 0.0352 - accuracy: 0.9903 - val_loss: 0.2742 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0403 - accuracy: 0.9903 - val_loss: 0.3543 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 3s 879ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 1.1526 - val_accuracy: 0.6818 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0190 - accuracy: 0.9903 - val_loss: 0.5936 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0137 - accuracy: 0.9903 - val_loss: 0.6248 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 4s 913ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 3s 875ms/step - loss: 0.0796 - accuracy: 0.9806 - val_loss: 0.3935 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 4s 890ms/step - loss: 0.0196 - accuracy: 0.9903 - val_loss: 0.6554 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9709 - val_loss: 0.5460 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 3s 903ms/step - loss: 0.0444 - accuracy: 0.9806 - val_loss: 1.3455 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0593 - accuracy: 0.9903 - val_loss: 0.6812 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.0193 - accuracy: 0.9922 - val_loss: 0.2945 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.1536 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0595 - accuracy: 0.9903 - val_loss: 0.1566 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 3s 895ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 3s 802ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.4407 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 3s 898ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.8391 - val_accuracy: 0.6364 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.2861 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.3958 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 3s 885ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.0419 - accuracy: 0.9806 - val_loss: 0.1761 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 4s 900ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.0556 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 3s 895ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 3s 807ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.2338 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 3s 907ms/step - loss: 0.0210 - accuracy: 0.9806 - val_loss: 0.2550 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 4s 974ms/step - loss: 0.0396 - accuracy: 0.9903 - val_loss: 0.3357 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 3s 921ms/step - loss: 0.0194 - accuracy: 0.9903 - val_loss: 0.6893 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 3s 894ms/step - loss: 0.1273 - accuracy: 0.9417 - val_loss: 0.5699 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 6s 2s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 3s 865ms/step - loss: 0.1986 - accuracy: 0.9709 - val_loss: 0.7902 - val_accuracy: 0.7727 - lr: 5.0000e-04\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 3s 715ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0920 - accuracy: 0.9806 - val_loss: 0.4851 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 4s 882ms/step - loss: 0.0526 - accuracy: 0.9709 - val_loss: 0.3924 - val_accuracy: 0.8182 - lr: 5.0000e-04\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 3s 800ms/step - loss: 0.0996 - accuracy: 0.9453 - val_loss: 3.6806 - val_accuracy: 0.5455 - lr: 5.0000e-04\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 6.3543 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 5.0771 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 3s 899ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.6364 - lr: 5.0000e-04\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 3s 905ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8636 - lr: 5.0000e-04\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 4s 891ms/step - loss: 0.0189 - accuracy: 0.9903 - val_loss: 0.1563 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 3s 929ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 3.6460e-04 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 0.6915 - accuracy: 0.8657\n",
            "3/3 [==============================] - 1s 176ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           F       0.82      0.94      0.87        33\n",
            "           M       0.93      0.79      0.86        34\n",
            "\n",
            "    accuracy                           0.87        67\n",
            "   macro avg       0.87      0.87      0.87        67\n",
            "weighted avg       0.87      0.87      0.87        67\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy manually\n",
        "manual_accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "print(f\"Manual Accuracy: {manual_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdPwni8kLXg3",
        "outputId": "f927b45e-1265-46ea-f6d9-9f2480f635aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Accuracy: 86.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "clf_model.save('O_fine_tune_87.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-FCw-QaHEzw",
        "outputId": "99ee0d7d-ee90-4bc6-e8a5-1790dafb8418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = metrics.confusion_matrix(y_true=true_classes, y_pred=predicted_classes)"
      ],
      "metadata": {
        "id": "Q8-l1l5mJeca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=class_labels)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3sLiyX4JHMuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aKmR-0kvHOml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "568tBKuhHQix"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}